\documentclass[10pt,letterpaper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[top=0.25in, bottom=0.25in, left=0.4in, right=0.4in]{geometry}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage{array}

% Disable all paragraph indentation
\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt}
\pagestyle{empty}

% Section title formatting - clean underline style with better spacing
\titleformat{\section}
  {\vspace{0.5pt}\scshape\large\bfseries\raggedright}
  {}{0em}
  {}
  [\titlerule\vspace{0.5pt}]

% Adjust section top/bottom spacing for better breathing room
\titlespacing{\section}{0pt}{*0.8}{*0.6}

% Better spaced bullet points - improved from original but still compact
\setlist[itemize]{
  label=\textbullet,
  leftmargin=15pt,
  labelwidth=10pt,
  labelsep=5pt,
  itemsep=0pt,
  parsep=0pt,
  topsep=0pt,
  partopsep=0pt
}

% No link colors
\hypersetup{
  colorlinks=false,
  pdfborder={0 0 0}
}

\begin{document}

% Header with better spacing
\begin{center}
  {\LARGE\textbf{Matt McManus}}\\[4pt]
  \footnotesize
  mattmcmanus41@gmail.com \textbar{} mmcmanus1.github.io\\[2pt]
  % linkedin.com/in/mattmcm \textbar{} github.com/mmcmanus1\\[2pt]
  \textbf{Citizenship:} U.S Citizen \textbar{} \textbf{Location:} New York, NY
\end{center}

\vspace{4pt}

\section{Summary}
\small

Research-oriented ML engineer focused on structure-aware learning and reliable decision systems---leakage-safe evaluation, probability calibration, and mechanistic probes for LLM agents in macro settings. MIT (Julia Lab) thesis on physics-informed INS; Two Sigma factor research with decorrelation and rigorous OOS walk-forward validation.



\vspace{3pt}

\section{Education}
\small

\textbf{Massachusetts Institute of Technology} \hfill Cambridge, MA\\[1pt]
\textit{Master of Engineering in Computer Science, GPA: 5.0/5.0} \hfill \textit{Aug. 2023 - Jun. 2024}
\begin{itemize}[topsep=0pt]
  \item Thesis: Physics-informed neural ODEs for inertial navigation systems with Prof. Alan Edelman (Julia Lab)
\end{itemize}

\vspace{0.5pt}

\textit{Bachelor of Science in Mathematics \& Computer Science} \hfill \textit{Aug. 2019 - Feb. 2024}
\begin{itemize}[topsep=0pt]
  \item \textsc{Graduate/Research}: Modeling with ML, LLMs \& Beyond, Multi-Agent Comm., Scientific ML, Stat. Learning Theory
  \item \textsc{Math/Theory}: Probability, Linear Algebra, Optimization, Algorithms, Statistics
  \item Activities: MIT Varsity Squash, MIT Pokerbots President, MIT Bitcoin Club, HKN Tutor
\end{itemize}

\vspace{3pt}

\section{Experience}
\small



\textbf{Bridgewater Associates — AIA Labs} \hfill New York, NY\\[1pt]
\textit{Machine Learning Engineer} \hfill \textit{Sept. 2024 -- Dec. 2025}
\begin{itemize}[topsep=0pt]
  \item Framed LLM reliability as calibration; posed hypotheses on dispersion, selective prediction, and prompt/program search.
  \item Built time-keyed, no-peek evaluation (recency gates, allowlists); ran walk-forward studies with Brier and log-loss.
  \item Evaluated Platt/isotonic calibration and LLM-as-Judge probes; documented failure modes; scaled via FastAPI/K8s.
\end{itemize}


% \textbf{Bridgewater Associates} \hfill New York, NY\\[1pt]
% \textit{ML Engineer - AIA Labs} \hfill \textit{Sept. 2024 - Present}
% \begin{itemize}[topsep=0pt]
%   \item Lead development of a systematic 
%   Lead development of proprietary AI models for macro-investing using \textbf{LLMs} and \textbf{RL} to generate alpha
%   \item Built "no-peek" data-windowing pipeline keyed to news\_end\_date, speeding thematic analysis \textbf{4x}
%   \item Developing transformer now-casting models blending alt-data with market signals; cut GDP-RMSE \textbf{15\%}
%   \item Build quantitative research infrastructure for \textbf{factor discovery} and \textbf{regime detection}, processing petabytes of data for \textbf{\$150B+ AUM}
%   \item Collaborate with Daniel Kang to benchmark internal temporal search system for systematic investing
% \end{itemize}

\vspace{0.5pt}

\textit{Investment Engineer Intern} \hfill \textit{Jun. 2023 - Aug. 2023}
\begin{itemize}[topsep=0pt]
  \item Developed data models and \textbf{algorithmic systems} to solve complex investment problems
  \item Designed statistical instruments for analyzing macroeconomic business cycles
\end{itemize}

\vspace{0.5pt}


\textbf{Two Sigma} \hfill New York, NY\\[1pt]
\textit{Quantitative Researcher (Part-time)} \hfill \textit{Jan. 2024 -- Jun. 2024}
\begin{itemize}
  \item Developed \textbf{cross-sectional alphas}; factor-neutral (beta/sector/size) and validated via rolling \textbf{OOS rank IC and IR}.
  \item Designed feature- and learner-level \textbf{decorrelation} (orthogonalization,
        column subsampling, correlation-penalized loss).
  \item Built a \textbf{leakage-safe} walk-forward pipeline with rolling normalization,
        liquidity-weighted scoring, and reproducible backtests/ablations.
\end{itemize}

% \textbf{Two Sigma} \hfill New York, NY\\[1pt]
% \textit{Quantitative Research (Part-time)} \hfill \textit{Jan. 2023 - Jun. 2024}
% \begin{itemize}[topsep=0pt]
%   \item Conducted fast-cycle experiments on \textbf{factor discovery} and \textbf{regime detection} for systematic trading
%   \item Developed ML models for alternative data analysis and signal generation, improving alpha decay by \textbf{30\%}
%   \item Researched high-frequency market microstructure patterns for alpha generation
% \end{itemize}

\vspace{0.5pt}

\textbf{MIT CSAIL — Julia Lab (Advisor: Alan Edelman)} \hfill Cambridge, MA\\[1pt]
\textit{Graduate Researcher — Scientific ML \& INS} \hfill \textit{Sep. 2023 -- Jun. 2024}
\begin{itemize}[topsep=0pt]
  \item Built Julia \textbf{physics-informed neural ODEs} for strapdown INS and cut 3D RMSE by \textbf{63\%} vs tuned EKF.
  \item Developed IMU simulation harness enabling \textbf{100+ walk-forward tests} daily with automated robustness checks.
  \item Open-sourced reproducible pipelines with CI, adopted by Leidos for navigation-grade sensor validation.
\end{itemize}



\textbf{MIT CSAIL — ALFA (Advisor: Una-May O'Reilly)} \hfill Cambridge, MA\\[1pt]
\textit{Undergraduate Researcher — LLMs for Cyber Defense} \hfill \textit{Sep. 2022 -- Jun. 2023}
\begin{itemize}[topsep=0pt]
  \item Built \textbf{graph-based cyber-defense simulator}; used GPT-3 for anomaly detection and attack pathing.
  \item Ran controlled studies across 50+ network topologies; achieved \textbf{2x faster} decision latency vs RL baselines.
  \item Prototyped \textbf{neuro-symbolic} layers for interpretability; saved resources by pivoting after rigorous A/B testing.
\end{itemize}


\vspace{4pt}

\section{Selected Research}
\small

\textbf{AIA Forecaster: LLM-Based Judgmental Forecasting} \hfill \textit{Bridgewater, 2025}\\[0pt]
\textit{Technical Report; LLM Agents, Calibration, Forecasting}
\begin{itemize}[topsep=0pt]
  \item LLM forecasting with agentic search, supervisor reconciliation, and calibration; matched superforecasters on ForecastBench.
  \item Ensemble with market consensus beats consensus alone; first expert-level AI forecasting at scale.
\end{itemize}

\vspace{0.5pt}

\textbf{How Do Transformers ``Do'' Math? Interpretability for Linear Regression} \hfill \textit{MIT, 2024}\\[0pt]
\textit{Course Research Project / Poster; Mechanistic Interpretability, Probing \& Interventions}
\begin{itemize}[topsep=0pt]
  \item Showed transformers encode/use task intermediates (slope $w$) via features; tied encoding to performance via probing
  \item Provided causal evidence via reverse probes + interventions (forcing $w \to w'$ predictably shifts outputs)
\end{itemize}


\vspace{0.5pt}

\textit{Full research portfolio:} mmcmanus1.github.io/research/

\vspace{4pt}

\section{Technical Skills}
\small

\textbf{ML/AI:} PyTorch · TensorFlow · Hugging Face · Transformers/LLMs · Reinforcement Learning · Scientific ML · XGBoost\\[1pt]
\textbf{Programming:} Python · Julia · C++ · Scala · Java · Go · SQL/Spark · JavaScript · R\\[1pt]
\textbf{Infrastructure:} AWS · Docker · Kubernetes · Git · CI/CD · Distributed Systems · PostgreSQL\\[1pt]
\textbf{Finance:} Quantitative Research · Factor Models · Backtesting · Risk Management

\vspace{4pt}

\section{Leadership \& Achievements}
\small

\textbf{MIT Pokerbots President:} Led Harvard-MIT ML poker competition (\textbf{250+} students), secured \textbf{\$100k+} sponsorships\\[1pt]
\textbf{MIT Phi Kappa Theta President:} Led fraternity operations and member development\\[1pt]
\textbf{MIT Varsity Squash:} Achieved National Team Ranking of \textbf{16th} in U.S. (2023-2024), 4-year starter

\vfill
\end{document}